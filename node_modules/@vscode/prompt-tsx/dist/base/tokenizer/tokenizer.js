"use strict";
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation and GitHub. All rights reserved.
 *--------------------------------------------------------------------------------------------*/
Object.defineProperty(exports, "__esModule", { value: true });
exports.AnyTokenizer = void 0;
const openai_1 = require("../openai");
class AnyTokenizer {
    countTokens;
    constructor(countTokens, mode) {
        this.countTokens = countTokens;
        if (mode !== 'vscode') {
            throw new Error('`mode` must be set to vscode when using vscode.LanguageModelChat as the tokenizer');
        }
    }
    async tokenLength(text, token) {
        return this.countTokens(text, token);
    }
    async countMessageTokens(message) {
        const vscode = await Promise.resolve().then(() => require('vscode'));
        return this.countTokens({
            role: this.toChatRole(message.role),
            content: [new vscode.LanguageModelTextPart(this.extractText(message))],
            name: 'name' in message ? message.name : undefined,
        });
    }
    extractText(message) {
        if (message.content instanceof Array) {
            return message.content.map(c => 'text' in c ? c.text : '').join('');
        }
        return message.content;
    }
    toChatRole(role) {
        switch (role) {
            case openai_1.ChatRole.User:
                return 1;
            case openai_1.ChatRole.Assistant:
                return 2;
            case openai_1.ChatRole.System:
                return 1;
            case openai_1.ChatRole.Function:
                return 1;
            case openai_1.ChatRole.Tool:
                return 1;
        }
    }
}
exports.AnyTokenizer = AnyTokenizer;
